{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stylegan(object):\n",
    "    def __init__(self, session, output_resolution=256):\n",
    "        self.sess = session\n",
    "        self.output_resolution = output_resolution\n",
    "        self.num_style_blocks = 0\n",
    "        self.num_discriminator_blocks = 0\n",
    "        self.num_to_rgbs = 0\n",
    "        self.num_from_rgbs = 0\n",
    "        self.num_downsamples = 0\n",
    "        \n",
    "        self.conv_weights = []\n",
    "        self.w_transforms = []\n",
    "        \n",
    "        self.latent_w = tf.placeholder(\n",
    "            shape=[None, 512],\n",
    "            dtype=tf.float32\n",
    "        )\n",
    "        \n",
    "        self.generator_out = self.generator(self.latent_w)\n",
    "        self.discriminator_out = self.discriminator(self.generator_out)\n",
    "        \n",
    "    def latentZMapper(self, Z_in, depth=8):\n",
    "        result = None\n",
    "        for i in range(depth):\n",
    "            W = tf.get_variable(\n",
    "                \"W_mapper_\" + str(i),\n",
    "                [512, 512],\n",
    "                initializer=tf.initializers.random_normal(stddev=0.3)\n",
    "            )\n",
    "            b = tf.get_variable(\n",
    "                \"b_mapper_\" + str(i),\n",
    "                [512,],\n",
    "                initializer=tf.initializers.random_normal(stddev=0.3)\n",
    "            )\n",
    "            \n",
    "            if i == 0:\n",
    "                result = tf.nn.relu(tf.matmul(Z_in, W) + b)\n",
    "            else:\n",
    "                result = tf.nn.relu(tf.matmul(result, W) + b)\n",
    "                \n",
    "        return result\n",
    "        \n",
    "    def generator(self, W_in):\n",
    "        with tf.variable_scope(\"generator\") as vs:\n",
    "            self.constant_input = tf.get_variable(\n",
    "                \"c_1\",\n",
    "                [4, 4, 512],\n",
    "                initializer=tf.initializers.orthogonal\n",
    "            )\n",
    "            \n",
    "            batch_size = tf.shape(W_in)[0]\n",
    "            \n",
    "            tiled_constant_input = tf.tile(\n",
    "                tf.expand_dims(\n",
    "                    self.constant_input, axis=0\n",
    "                ),\n",
    "                [batch_size, 1, 1, 1]\n",
    "            )\n",
    "            \n",
    "            print(\"tiled constant input:\", tiled_constant_input)\n",
    "            \n",
    "            block_4_2 = self.styleBlock(\n",
    "                tiled_constant_input,\n",
    "                W_in,\n",
    "                num_input_channels=512,\n",
    "                #1\n",
    "                num_output_channels=512\n",
    "            )\n",
    "            \n",
    "            to_rgb_1 = self.toRgb(block_4_2, 4, 4, 512)\n",
    "            \n",
    "            block_8_1 = self.styleBlock(\n",
    "                block_4_2,\n",
    "                W_in,\n",
    "                num_input_channels=512,\n",
    "                #2\n",
    "                num_output_channels=512,\n",
    "                upsample=True\n",
    "            )\n",
    "            \n",
    "            block_8_2 = self.styleBlock(\n",
    "                block_8_1,\n",
    "                W_in,\n",
    "                num_input_channels=512,\n",
    "                #3\n",
    "                num_output_channels=512\n",
    "            )\n",
    "            \n",
    "            to_rgb_2 = self.toRgb(block_8_2, 8, 8, 512) + self.upsample(to_rgb_1)\n",
    "            \n",
    "            block_16_1 = self.styleBlock(\n",
    "                block_8_2,\n",
    "                W_in,\n",
    "                num_input_channels=512,\n",
    "                #4\n",
    "                num_output_channels=512,\n",
    "                upsample=True\n",
    "            )\n",
    "            \n",
    "            block_16_2 = self.styleBlock(\n",
    "                block_16_1,\n",
    "                W_in,\n",
    "                num_input_channels=512,\n",
    "                #5\n",
    "                num_output_channels=512,\n",
    "            )\n",
    "            \n",
    "            to_rgb_3 = self.toRgb(block_16_2, 16, 16, 512) + self.upsample(to_rgb_2)\n",
    "            \n",
    "            block_32_1 = self.styleBlock(\n",
    "                block_16_2,\n",
    "                W_in,\n",
    "                num_input_channels=512,\n",
    "                #6\n",
    "                num_output_channels=512,\n",
    "                upsample=True\n",
    "            )\n",
    "            \n",
    "            block_32_2 = self.styleBlock(\n",
    "                block_32_1,\n",
    "                W_in,\n",
    "                num_input_channels=512,\n",
    "                #7\n",
    "                num_output_channels=512,\n",
    "            )\n",
    "            \n",
    "            to_rgb_4 = self.toRgb(block_32_2, 32, 32, 512) + self.upsample(to_rgb_3)\n",
    "            \n",
    "            block_64_1 = self.styleBlock(\n",
    "                block_32_2,\n",
    "                W_in,\n",
    "                num_input_channels=512,\n",
    "                #8\n",
    "                num_output_channels=512,\n",
    "                upsample=True\n",
    "            )\n",
    "            \n",
    "            block_64_2 = self.styleBlock(\n",
    "                block_64_1,\n",
    "                W_in,\n",
    "                num_input_channels=512,\n",
    "                num_output_channels=256,\n",
    "            )\n",
    "            print(\"block_64_2:\", block_64_2)\n",
    "            to_rgb_5 = self.toRgb(block_64_2, 64, 64, 256) + self.upsample(to_rgb_4)\n",
    "            \n",
    "            block_128_1 = self.styleBlock(\n",
    "                block_64_2,\n",
    "                W_in,\n",
    "                num_input_channels=256,\n",
    "                num_output_channels=256,\n",
    "                upsample=True\n",
    "            )\n",
    "            \n",
    "            block_128_2 = self.styleBlock(\n",
    "                block_128_1,\n",
    "                W_in,\n",
    "                num_input_channels=256,\n",
    "                num_output_channels=128,\n",
    "            )\n",
    "            \n",
    "            to_rgb_6 = self.toRgb(block_128_2, 128, 128, 128) + self.upsample(to_rgb_5)\n",
    "            \n",
    "            block_256_1 = self.styleBlock(\n",
    "                block_128_2,\n",
    "                W_in,\n",
    "                num_input_channels=128,\n",
    "                num_output_channels=128,\n",
    "                upsample=True\n",
    "            )\n",
    "            \n",
    "            block_256_2 = self.styleBlock(\n",
    "                block_256_1,\n",
    "                W_in,\n",
    "                num_input_channels=128,\n",
    "                num_output_channels=64,\n",
    "            )\n",
    "            \n",
    "            to_rgb_7 = self.toRgb(block_256_2, 256, 256, 64) + self.upsample(to_rgb_6)\n",
    "            \n",
    "            return to_rgb_7\n",
    "            \n",
    "    def discriminator(self, rgb_in):\n",
    "        with tf.variable_scope(\"discriminator\") as vs:\n",
    "            from_rgb_1 = self.fromRgb(rgb_in, 256, 256, 16)\n",
    "            \n",
    "            downsample_1 = self.downsample(from_rgb_1, 16)\n",
    "            block_256_1 = self.discriminatorBlock(\n",
    "                from_rgb_1,\n",
    "                16,\n",
    "                32\n",
    "            )\n",
    "            \n",
    "            res_1 = downsample_1 + block_256_1\n",
    "            \n",
    "            downsample_2 = self.downsample(res_1, 32)\n",
    "            block_128_2 = self.discriminatorBlock(\n",
    "                res_1,\n",
    "                32,\n",
    "                64\n",
    "            )\n",
    "            \n",
    "            res_2 = downsample_2 + block_128_2\n",
    "            \n",
    "            downsample_3 = self.downsample(res_2, 64)\n",
    "            block_64_3 = self.discriminatorBlock(\n",
    "                res_2,\n",
    "                64,\n",
    "                128\n",
    "            )\n",
    "            \n",
    "            res_3 = downsample_3 + block_64_3\n",
    "            \n",
    "            downsample_4 = self.downsample(res_3, 128)\n",
    "            block_32_4 = self.discriminatorBlock(\n",
    "                res_3,\n",
    "                128,\n",
    "                256\n",
    "            )\n",
    "            \n",
    "            res_4 = downsample_4 + block_32_4\n",
    "            \n",
    "            downsample_5 = self.downsample(res_4, 256)\n",
    "            block_16_5 = self.discriminatorBlock(\n",
    "                res_4,\n",
    "                256,\n",
    "                512\n",
    "            )\n",
    "            \n",
    "            res_5 = downsample_5 + block_16_5\n",
    "            \n",
    "            downsample_6 = self.downsample(res_5, 512, 512)\n",
    "            block_8_6 = self.discriminatorBlock(\n",
    "                res_5,\n",
    "                512,\n",
    "                512\n",
    "            )\n",
    "            \n",
    "            res_6 = downsample_6 + block_8_6\n",
    "            \n",
    "            downsample_7 = self.downsample(res_6, 512, 512)\n",
    "            block_4_7 = self.discriminatorBlock(\n",
    "                res_6,\n",
    "                512,\n",
    "                512\n",
    "            )\n",
    "            \n",
    "            res_7 = downsample_7 + block_4_7\n",
    "            \n",
    "            conv_w_a = tf.get_variable(\n",
    "                \"conv_w_disc_end_3x3\",\n",
    "                [3, 3, 512, 512],\n",
    "                initializer=tf.initializers.orthogonal\n",
    "            )\n",
    "            \n",
    "            conv_out_1 = tf.nn.leaky_relu(\n",
    "                tf.nn.conv2d(res_7, conv_w_a, padding=\"SAME\"),\n",
    "                alpha=0.2\n",
    "            )\n",
    "            \n",
    "            conv_w_b = tf.get_variable(\n",
    "                \"conv_w_disc_end_4x4\",\n",
    "                [4, 4, 512, 512],\n",
    "                initializer=tf.initializers.orthogonal\n",
    "            )\n",
    "            \n",
    "            conv_out_2 = tf.nn.leaky_relu(\n",
    "                tf.nn.conv2d(conv_out_1, conv_w_b, padding=\"SAME\"),\n",
    "                alpha=0.2\n",
    "            )\n",
    "            \n",
    "            batch_size = tf.shape(conv_out_2)[0]\n",
    "            \n",
    "            conv_outputs_flat = tf.reshape(conv_out_2, shape=[batch_size, -1])\n",
    "            \n",
    "            W_fc = tf.get_variable(\n",
    "                \"fully_connected_W_disc_end\",\n",
    "                [512, 1],\n",
    "                initializer=tf.initializers.orthogonal\n",
    "            )\n",
    "            \n",
    "            b_fc = tf.get_variable(\n",
    "                \"fully_connected_b_disc_end\",\n",
    "                [1],\n",
    "                initializer=tf.initializers.random_normal\n",
    "            )\n",
    "            \n",
    "            disc_out = tf.nn.leaky_relu(\n",
    "                tf.matmul(conv_outputs_flat, W_fc) + b_fc\n",
    "            )\n",
    "            \n",
    "            return disc_out\n",
    "            \n",
    "    def discriminatorBlock(self, V_in, num_input_channels, num_output_channels, downsample=True):\n",
    "        # V_in        --> [batch_size, height, width, num_input_channels]\n",
    "        # latent_w    --> [batch_size, 512]\n",
    "        #    num_input_channels  = number of input feature maps\n",
    "        #    num_output_channels = number of output feature maps\n",
    "        self.num_discriminator_blocks += 1\n",
    "        \n",
    "        conv_weight_a = tf.get_variable(\n",
    "            \"conv_w_disc_a_\" + str(self.num_discriminator_blocks),\n",
    "            [3, 3, num_input_channels, num_input_channels],\n",
    "            initializer=tf.initializers.orthogonal\n",
    "        )\n",
    "        \n",
    "        V_out_a = tf.nn.leaky_relu(\n",
    "            tf.nn.conv2d(V_in, conv_weight_a, padding=\"SAME\"),\n",
    "            alpha=0.2\n",
    "        )\n",
    "        \n",
    "        conv_weight_b = tf.get_variable(\n",
    "            \"conv_w_disc_b_\" + str(self.num_discriminator_blocks),\n",
    "            [3, 3, num_input_channels, num_output_channels],\n",
    "            initializer=tf.initializers.orthogonal\n",
    "        )\n",
    "        \n",
    "        V_out_b = tf.nn.leaky_relu(\n",
    "            tf.nn.conv2d(V_out_a, conv_weight_b, padding=\"SAME\"),\n",
    "            alpha=0.2\n",
    "        )\n",
    "        \n",
    "        V_out = self.downsample(V_out_b, num_output_channels, num_output_channels)\n",
    "        \n",
    "        return V_out\n",
    "            \n",
    "    def styleBlock(self, V_in, latent_w, num_input_channels, num_output_channels, upsample=False):\n",
    "        # V_in        --> [batch_size, height, width, num_input_channels]\n",
    "        # latent_w    --> [batch_size, 512]\n",
    "        #    num_input_channels  = number of input feature maps\n",
    "        #    num_output_channels = number of output feature maps\n",
    "        self.num_style_blocks += 1\n",
    "        \n",
    "        if upsample:\n",
    "            V_in = self.upsample(V_in)\n",
    "        \n",
    "        A = tf.get_variable(\n",
    "            \"A_style\" + str(self.num_style_blocks),\n",
    "            [512, num_input_channels],\n",
    "            #[512, num_output_channels],\n",
    "            initializer=tf.initializers.orthogonal\n",
    "        )\n",
    "        \n",
    "        conv_weight = tf.get_variable(\n",
    "            \"conv_w_style\" + str(self.num_style_blocks),\n",
    "            [3, 3, num_input_channels, num_output_channels],\n",
    "            initializer=tf.initializers.orthogonal\n",
    "        )\n",
    "        \n",
    "        # Affine transformation of latent space vector.\n",
    "        scale = tf.matmul(latent_w, A)\n",
    "        \n",
    "        # Scale input feature map acros input channels by the affine transformation\n",
    "        # of the latent space input.\n",
    "        print(\"##########\")\n",
    "        print(\"scale input feature map\")\n",
    "        print(\"scale\", scale)\n",
    "        print(\"V_in\", V_in)\n",
    "        V_in_scaled = tf.einsum(\"bi,bhwi->bhwi\", scale, V_in)\n",
    "        \n",
    "        V_out = tf.nn.conv2d(V_in_scaled, conv_weight, padding=\"SAME\")\n",
    "        print(\"V_out:\", V_out)\n",
    "        # This increases the number of weights by a factor of batch_size,\n",
    "        # which is weird.\n",
    "        #print(\"#########\")\n",
    "        print(\"calculate sigma_j\")\n",
    "        print(\"scale\", scale)\n",
    "        print(\"conv_weight\", conv_weight)\n",
    "        #modul_conv_weight = tf.einsum(\"bc,hwjc->bhwjc\", scale, conv_weight)\n",
    "        modul_conv_weight = tf.einsum(\"bj,hwjc->bhwjc\", scale, conv_weight)\n",
    "        sigma_j = tf.sqrt(tf.reduce_sum(tf.square(modul_conv_weight), axis=[1, 2, 3]) + 1e-6)\n",
    "        \n",
    "        #print(\"#############\")\n",
    "        print(\"calculate output\")\n",
    "        print(\"V_in_scaled\", V_in_scaled)\n",
    "        print(\"sigma_j\", sigma_j)\n",
    "        # Need to add biases and broadcast noise.\n",
    "        V_out_scaled = tf.nn.leaky_relu(\n",
    "            tf.einsum(\"bhwj,bj->bhwj\", V_out, sigma_j),\n",
    "            alpha=0.2\n",
    "        )\n",
    "\n",
    "        return V_out_scaled\n",
    "    \n",
    "    def upsample(self, V_in):\n",
    "        # Tested with the channel dimension.\n",
    "        fm_size = tf.shape(V_in)\n",
    "        batch_size = fm_size[0]\n",
    "        h = fm_size[1]\n",
    "        w = fm_size[2]\n",
    "        c = fm_size[3]\n",
    "        V_in_a = tf.concat([V_in, V_in,], axis=2)\n",
    "        V_in_b = tf.reshape(V_in_a, [batch_size, 2*h, w, c])\n",
    "\n",
    "        V_in_c = tf.transpose(V_in_b, perm=[0, 2, 1, 3])\n",
    "        V_in_d = tf.concat([V_in_c, V_in_c], axis=2)\n",
    "        V_out = tf.transpose(tf.reshape(V_in_d, [batch_size, 2*h, 2*w, c]), perm=[0, 2, 1, 3])\n",
    "        \n",
    "        return V_out\n",
    "    \n",
    "    def downsample(self, V_in, input_channels, output_channels=None):\n",
    "        self.num_downsamples += 1\n",
    "        \n",
    "        if output_channels is None:\n",
    "            output_channels = 2*input_channels\n",
    "        \n",
    "        channel_increase = tf.get_variable(\n",
    "            \"channel_increaser\" + str(self.num_downsamples),\n",
    "            [1, 1, input_channels, output_channels]\n",
    "        )\n",
    "        \n",
    "        V_larger = tf.nn.relu(\n",
    "            tf.nn.conv2d(V_in, channel_increase, padding=\"SAME\")\n",
    "        )\n",
    "        \n",
    "        V_out = tf.nn.max_pool2d(V_larger, ksize=2, strides=2, padding=\"VALID\")\n",
    "        return V_out\n",
    "    \n",
    "    def toRgb(self, V_in, h, w, c):\n",
    "        '''\n",
    "        Convert an NxNxC output block to an RGB image with dimensions\n",
    "        NxNx3.\n",
    "        '''\n",
    "        \n",
    "        self.num_to_rgbs += 1\n",
    "        \n",
    "        #V_in_shape = tf.shape(V_in)\n",
    "        #batch_size = V_in_shape[0]\n",
    "        #h = V_in_shape[1]\n",
    "        #w = V_in_shape[2]\n",
    "        #c = V_in_shape[3]\n",
    "\n",
    "        \n",
    "        to_rgb = tf.get_variable(\n",
    "            \"to_rgb\" + str(self.num_to_rgbs),\n",
    "            [h, w, c, 3],\n",
    "            initializer=tf.initializers.random_normal\n",
    "        )\n",
    "        print(\"###############\")\n",
    "        print(\"V_in:\", V_in)\n",
    "        print(\"to_rgb:\", to_rgb)\n",
    "        rgb_out = tf.nn.relu(\n",
    "            tf.nn.conv2d(V_in, to_rgb, padding=\"SAME\")\n",
    "        )\n",
    "        \n",
    "        return rgb_out\n",
    "    \n",
    "    def fromRgb(self, V_in, h, w, c):\n",
    "        '''\n",
    "        Convert an NxNx3 output block to an feature map with dimensions\n",
    "        NxNxC.\n",
    "        '''\n",
    "        \n",
    "        self.num_from_rgbs += 1\n",
    "        \n",
    "        from_rgb = tf.get_variable(\n",
    "            \"from_rgb\" + str(self.num_from_rgbs),\n",
    "            [h, w, 3, c],\n",
    "            initializer=tf.initializers.random_normal\n",
    "        )\n",
    "        \n",
    "        feature_map_out = tf.nn.relu(\n",
    "            tf.nn.conv2d(V_in, from_rgb, padding=\"SAME\")\n",
    "        )\n",
    "        \n",
    "        return feature_map_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiled constant input: Tensor(\"generator/Tile:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "##########\n",
      "scale input feature map\n",
      "scale Tensor(\"generator/MatMul:0\", shape=(?, 512), dtype=float32)\n",
      "V_in Tensor(\"generator/Tile:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "V_out: Tensor(\"generator/Conv2D:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "calculate sigma_j\n",
      "scale Tensor(\"generator/MatMul:0\", shape=(?, 512), dtype=float32)\n",
      "conv_weight <tf.Variable 'generator/conv_w_style1:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "calculate output\n",
      "V_in_scaled Tensor(\"generator/einsum/transpose_2:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "sigma_j Tensor(\"generator/Sqrt:0\", shape=(?, 512), dtype=float32)\n",
      "###############\n",
      "V_in: Tensor(\"generator/LeakyRelu:0\", shape=(?, 4, 4, 512), dtype=float32)\n",
      "to_rgb: <tf.Variable 'generator/to_rgb1:0' shape=(4, 4, 512, 3) dtype=float32_ref>\n",
      "##########\n",
      "scale input feature map\n",
      "scale Tensor(\"generator/MatMul_1:0\", shape=(?, 512), dtype=float32)\n",
      "V_in Tensor(\"generator/transpose_1:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "V_out: Tensor(\"generator/Conv2D_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "calculate sigma_j\n",
      "scale Tensor(\"generator/MatMul_1:0\", shape=(?, 512), dtype=float32)\n",
      "conv_weight <tf.Variable 'generator/conv_w_style2:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "calculate output\n",
      "V_in_scaled Tensor(\"generator/einsum_3/transpose_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "sigma_j Tensor(\"generator/Sqrt_1:0\", shape=(?, 512), dtype=float32)\n",
      "##########\n",
      "scale input feature map\n",
      "scale Tensor(\"generator/MatMul_2:0\", shape=(?, 512), dtype=float32)\n",
      "V_in Tensor(\"generator/LeakyRelu_1:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "V_out: Tensor(\"generator/Conv2D_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "calculate sigma_j\n",
      "scale Tensor(\"generator/MatMul_2:0\", shape=(?, 512), dtype=float32)\n",
      "conv_weight <tf.Variable 'generator/conv_w_style3:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "calculate output\n",
      "V_in_scaled Tensor(\"generator/einsum_6/transpose_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "sigma_j Tensor(\"generator/Sqrt_2:0\", shape=(?, 512), dtype=float32)\n",
      "###############\n",
      "V_in: Tensor(\"generator/LeakyRelu_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "to_rgb: <tf.Variable 'generator/to_rgb2:0' shape=(8, 8, 512, 3) dtype=float32_ref>\n",
      "##########\n",
      "scale input feature map\n",
      "scale Tensor(\"generator/MatMul_3:0\", shape=(?, 512), dtype=float32)\n",
      "V_in Tensor(\"generator/transpose_5:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "V_out: Tensor(\"generator/Conv2D_5:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "calculate sigma_j\n",
      "scale Tensor(\"generator/MatMul_3:0\", shape=(?, 512), dtype=float32)\n",
      "conv_weight <tf.Variable 'generator/conv_w_style4:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "calculate output\n",
      "V_in_scaled Tensor(\"generator/einsum_9/transpose_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "sigma_j Tensor(\"generator/Sqrt_3:0\", shape=(?, 512), dtype=float32)\n",
      "##########\n",
      "scale input feature map\n",
      "scale Tensor(\"generator/MatMul_4:0\", shape=(?, 512), dtype=float32)\n",
      "V_in Tensor(\"generator/LeakyRelu_3:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "V_out: Tensor(\"generator/Conv2D_6:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "calculate sigma_j\n",
      "scale Tensor(\"generator/MatMul_4:0\", shape=(?, 512), dtype=float32)\n",
      "conv_weight <tf.Variable 'generator/conv_w_style5:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "calculate output\n",
      "V_in_scaled Tensor(\"generator/einsum_12/transpose_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "sigma_j Tensor(\"generator/Sqrt_4:0\", shape=(?, 512), dtype=float32)\n",
      "###############\n",
      "V_in: Tensor(\"generator/LeakyRelu_4:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "to_rgb: <tf.Variable 'generator/to_rgb3:0' shape=(16, 16, 512, 3) dtype=float32_ref>\n",
      "##########\n",
      "scale input feature map\n",
      "scale Tensor(\"generator/MatMul_5:0\", shape=(?, 512), dtype=float32)\n",
      "V_in Tensor(\"generator/transpose_9:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "V_out: Tensor(\"generator/Conv2D_8:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "calculate sigma_j\n",
      "scale Tensor(\"generator/MatMul_5:0\", shape=(?, 512), dtype=float32)\n",
      "conv_weight <tf.Variable 'generator/conv_w_style6:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "calculate output\n",
      "V_in_scaled Tensor(\"generator/einsum_15/transpose_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "sigma_j Tensor(\"generator/Sqrt_5:0\", shape=(?, 512), dtype=float32)\n",
      "##########\n",
      "scale input feature map\n",
      "scale Tensor(\"generator/MatMul_6:0\", shape=(?, 512), dtype=float32)\n",
      "V_in Tensor(\"generator/LeakyRelu_5:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "V_out: Tensor(\"generator/Conv2D_9:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "calculate sigma_j\n",
      "scale Tensor(\"generator/MatMul_6:0\", shape=(?, 512), dtype=float32)\n",
      "conv_weight <tf.Variable 'generator/conv_w_style7:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "calculate output\n",
      "V_in_scaled Tensor(\"generator/einsum_18/transpose_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "sigma_j Tensor(\"generator/Sqrt_6:0\", shape=(?, 512), dtype=float32)\n",
      "###############\n",
      "V_in: Tensor(\"generator/LeakyRelu_6:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "to_rgb: <tf.Variable 'generator/to_rgb4:0' shape=(32, 32, 512, 3) dtype=float32_ref>\n",
      "##########\n",
      "scale input feature map\n",
      "scale Tensor(\"generator/MatMul_7:0\", shape=(?, 512), dtype=float32)\n",
      "V_in Tensor(\"generator/transpose_13:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "V_out: Tensor(\"generator/Conv2D_11:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "calculate sigma_j\n",
      "scale Tensor(\"generator/MatMul_7:0\", shape=(?, 512), dtype=float32)\n",
      "conv_weight <tf.Variable 'generator/conv_w_style8:0' shape=(3, 3, 512, 512) dtype=float32_ref>\n",
      "calculate output\n",
      "V_in_scaled Tensor(\"generator/einsum_21/transpose_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "sigma_j Tensor(\"generator/Sqrt_7:0\", shape=(?, 512), dtype=float32)\n",
      "##########\n",
      "scale input feature map\n",
      "scale Tensor(\"generator/MatMul_8:0\", shape=(?, 512), dtype=float32)\n",
      "V_in Tensor(\"generator/LeakyRelu_7:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "V_out: Tensor(\"generator/Conv2D_12:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "calculate sigma_j\n",
      "scale Tensor(\"generator/MatMul_8:0\", shape=(?, 512), dtype=float32)\n",
      "conv_weight <tf.Variable 'generator/conv_w_style9:0' shape=(3, 3, 512, 256) dtype=float32_ref>\n",
      "calculate output\n",
      "V_in_scaled Tensor(\"generator/einsum_24/transpose_2:0\", shape=(?, ?, ?, 512), dtype=float32)\n",
      "sigma_j Tensor(\"generator/Sqrt_8:0\", shape=(?, 256), dtype=float32)\n",
      "block_64_2: Tensor(\"generator/LeakyRelu_8:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "###############\n",
      "V_in: Tensor(\"generator/LeakyRelu_8:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "to_rgb: <tf.Variable 'generator/to_rgb5:0' shape=(64, 64, 256, 3) dtype=float32_ref>\n",
      "##########\n",
      "scale input feature map\n",
      "scale Tensor(\"generator/MatMul_9:0\", shape=(?, 256), dtype=float32)\n",
      "V_in Tensor(\"generator/transpose_17:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "V_out: Tensor(\"generator/Conv2D_14:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "calculate sigma_j\n",
      "scale Tensor(\"generator/MatMul_9:0\", shape=(?, 256), dtype=float32)\n",
      "conv_weight <tf.Variable 'generator/conv_w_style10:0' shape=(3, 3, 256, 256) dtype=float32_ref>\n",
      "calculate output\n",
      "V_in_scaled Tensor(\"generator/einsum_27/transpose_2:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "sigma_j Tensor(\"generator/Sqrt_9:0\", shape=(?, 256), dtype=float32)\n",
      "##########\n",
      "scale input feature map\n",
      "scale Tensor(\"generator/MatMul_10:0\", shape=(?, 256), dtype=float32)\n",
      "V_in Tensor(\"generator/LeakyRelu_9:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "V_out: Tensor(\"generator/Conv2D_15:0\", shape=(?, ?, ?, 128), dtype=float32)\n",
      "calculate sigma_j\n",
      "scale Tensor(\"generator/MatMul_10:0\", shape=(?, 256), dtype=float32)\n",
      "conv_weight <tf.Variable 'generator/conv_w_style11:0' shape=(3, 3, 256, 128) dtype=float32_ref>\n",
      "calculate output\n",
      "V_in_scaled Tensor(\"generator/einsum_30/transpose_2:0\", shape=(?, ?, ?, 256), dtype=float32)\n",
      "sigma_j Tensor(\"generator/Sqrt_10:0\", shape=(?, 128), dtype=float32)\n",
      "###############\n",
      "V_in: Tensor(\"generator/LeakyRelu_10:0\", shape=(?, ?, ?, 128), dtype=float32)\n",
      "to_rgb: <tf.Variable 'generator/to_rgb6:0' shape=(128, 128, 128, 3) dtype=float32_ref>\n",
      "##########\n",
      "scale input feature map\n",
      "scale Tensor(\"generator/MatMul_11:0\", shape=(?, 128), dtype=float32)\n",
      "V_in Tensor(\"generator/transpose_21:0\", shape=(?, ?, ?, ?), dtype=float32)\n",
      "V_out: Tensor(\"generator/Conv2D_17:0\", shape=(?, ?, ?, 128), dtype=float32)\n",
      "calculate sigma_j\n",
      "scale Tensor(\"generator/MatMul_11:0\", shape=(?, 128), dtype=float32)\n",
      "conv_weight <tf.Variable 'generator/conv_w_style12:0' shape=(3, 3, 128, 128) dtype=float32_ref>\n",
      "calculate output\n",
      "V_in_scaled Tensor(\"generator/einsum_33/transpose_2:0\", shape=(?, ?, ?, 128), dtype=float32)\n",
      "sigma_j Tensor(\"generator/Sqrt_11:0\", shape=(?, 128), dtype=float32)\n",
      "##########\n",
      "scale input feature map\n",
      "scale Tensor(\"generator/MatMul_12:0\", shape=(?, 128), dtype=float32)\n",
      "V_in Tensor(\"generator/LeakyRelu_11:0\", shape=(?, ?, ?, 128), dtype=float32)\n",
      "V_out: Tensor(\"generator/Conv2D_18:0\", shape=(?, ?, ?, 64), dtype=float32)\n",
      "calculate sigma_j\n",
      "scale Tensor(\"generator/MatMul_12:0\", shape=(?, 128), dtype=float32)\n",
      "conv_weight <tf.Variable 'generator/conv_w_style13:0' shape=(3, 3, 128, 64) dtype=float32_ref>\n",
      "calculate output\n",
      "V_in_scaled Tensor(\"generator/einsum_36/transpose_2:0\", shape=(?, ?, ?, 128), dtype=float32)\n",
      "sigma_j Tensor(\"generator/Sqrt_12:0\", shape=(?, 64), dtype=float32)\n",
      "###############\n",
      "V_in: Tensor(\"generator/LeakyRelu_12:0\", shape=(?, ?, ?, 64), dtype=float32)\n",
      "to_rgb: <tf.Variable 'generator/to_rgb7:0' shape=(256, 256, 64, 3) dtype=float32_ref>\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 1024 and 512 for 'discriminator/add_5' (op: 'Add') with input shapes: [?,?,?,1024], [?,?,?,512].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1864\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 1024 and 512 for 'discriminator/add_5' (op: 'Add') with input shapes: [?,?,?,1024], [?,?,?,512].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-27fd379c636b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstylegan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-e844c06b2a49>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, output_resolution)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_w\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlatentZMapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-e844c06b2a49>\u001b[0m in \u001b[0;36mdiscriminator\u001b[0;34m(self, rgb_in)\u001b[0m\n\u001b[1;32m    237\u001b[0m             )\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mres_6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdownsample_6\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mblock_8_6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0mdownsample_7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m    385\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m--> 387\u001b[0;31m         \"Add\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m    388\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m     result = _dispatch.dispatch(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    786\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    787\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    789\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3614\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3615\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3616\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3617\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3618\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2025\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   2026\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 2027\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   2028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2029\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions must be equal, but are 1024 and 512 for 'discriminator/add_5' (op: 'Add') with input shapes: [?,?,?,1024], [?,?,?,512]."
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "s = stylegan(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(\n",
    "    np.array(\n",
    "        [\n",
    "            [[1,2,3],\n",
    "             [4,5,6],\n",
    "             [7,8,9]\n",
    "            ],\n",
    "            [[-1,-2,-3],\n",
    "             [-4,-5,-6],\n",
    "             [-7,-8,-9]\n",
    "            ],\n",
    "            [[1.2,2.2,3.2],\n",
    "             [4.2,5.2,6.2],\n",
    "             [7.2,8.2,9.2]\n",
    "            ],\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.concat([a, a,], axis=2)\n",
    "c = tf.reshape(b, [3,6,3])\n",
    "\n",
    "d = tf.transpose(c, perm=[0, 2, 1])\n",
    "e = tf.concat([d, d], axis=2)\n",
    "f = tf.transpose(tf.reshape(e, [3, 6, 6]), perm=[0, 2, 1])\n",
    "\n",
    "g = tf.stack([a, 2*a, 3.4*a], axis=3)\n",
    "h = tf.concat([g, g], axis=2)\n",
    "i = tf.reshape(h, [3, 6, 3, 3])\n",
    "j = tf.transpose(i, perm=[0, 2, 1, 3])\n",
    "k = tf.concat([j, j], axis=2)\n",
    "l = tf.transpose(tf.reshape(k, [3, 6, 6, 3]), perm=[0, 2, 1, 3])\n",
    "\n",
    "for i in range(3):\n",
    "    print(sess.run(l)[:, :, :, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(tf.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tf.tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(tf.transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(tf.stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tf.nn.max_pool2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tf.nn.conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(tf.concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.tile(tf.expand_dims(tf.constant([2,]), axis=1), [tf.constant(64), 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "help(tf.get_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
