{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stylegan(object):\n",
    "    def __init__(self, session, output_resolution=256):\n",
    "        self.sess = session\n",
    "        self.output_resolution = output_resolution\n",
    "        self.num_style_blocks = 0\n",
    "        \n",
    "        self.conv_weights = []\n",
    "        self.w_transforms = []\n",
    "        \n",
    "    def generator(self, W_in):\n",
    "        with tf.variable_scope(\"generator\") as vs:\n",
    "            block_1 = tf.get_variable(\n",
    "                \"w1v\",\n",
    "                [512, 4, 4],\n",
    "                initializer=tf.initializers.orthogonal\n",
    "            )\n",
    "            \n",
    "    def styleBlock(self, V_in, latent_w, num_input_channels, num_output_channels, upsample=False):\n",
    "        # V_in        --> [batch_size, height, width, num_input_channels]\n",
    "        # latent_w    --> [batch_size, 512]\n",
    "        # conv_weight --> [num_in_fm, num_out_fm, conv_dim]\n",
    "        #    num_in_fm  = number of input feature maps\n",
    "        #    num_out_fm = number of output feature maps\n",
    "        #    conv_dim   = dimension of convolution\n",
    "        self.num_style_blocks += 1\n",
    "        \n",
    "        A = tf.get_variable(\n",
    "            \"A_style\" + str(self.num_style_blocks),\n",
    "            [512, num_input_feature_maps],\n",
    "            initializer=tf.initializers.orthogonal\n",
    "        )\n",
    "        \n",
    "        conv_weight = tf.get_variable(\n",
    "            \"conv_w_style\" + str(self.num_style_blocks),\n",
    "            [3, 3, num_input_channels, num_output_channels],\n",
    "            initialier=tf.initializers.orthogonal\n",
    "        )\n",
    "        \n",
    "        # Affine transformation of latent space vector\n",
    "        scale = tf.matmul(A, latent_w)\n",
    "        \n",
    "        # Scale input feature map acros input channels by the affine transformation\n",
    "        # of the latent space input.\n",
    "        V_in_scaled = tf.einsum(\"bi,bhwi->bhwi\", scale, V_in)\n",
    "        \n",
    "        V_out = tf.nn.conv2d(V_in_scaled, conv_weight, padding=\"same\")\n",
    "        \n",
    "        # This increases the number of weights by a factor of batch_size,\n",
    "        # which is weird.\n",
    "        modul_conv_weight = tf.einsum(\"bi,ijk->bijk\", scale, conv_weight)\n",
    "        sigma_j = tf.sqrt(tf.reduce_sum(tf.square(modul_conv_weight), axis=[1, 3]) + 1e-6)\n",
    "        V_out_scaled = tf.nn.leaky_relu(\n",
    "            tf.einsum(\"bhwj,bj->bhwj\", V_in_scaled, sigma_j),\n",
    "            alpha=0.2\n",
    "        )\n",
    "\n",
    "        return V_out_scaled\n",
    "    \n",
    "    def upsample(self, V_in):\n",
    "        # Didn't test with the channel dimension yet... might be wrong.\n",
    "        fm_size = tf.shape(V_in)\n",
    "        batch_size, h, w, c = fm_size\n",
    "        V_in_a = tf.concat([V_in, V_in,], axis=3)\n",
    "        V_in_b = tf.reshape(V_in_a, [batch_size, 2*h, w, c])\n",
    "\n",
    "        V_in_c = tf.transpose(V_in_b, perm=[0, 2, 1, 3])\n",
    "        V_in_d = tf.concat([V_in_c, V_in_c], axis=3)\n",
    "        V_in_e = tf.transpose(tf.reshape(e, [batch_size, 2*h, 2*w, c]), perm=[0, 2, 1, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function reduce_sum_v1 in module tensorflow.python.ops.math_ops:\n",
      "\n",
      "reduce_sum_v1(input_tensor, axis=None, keepdims=None, name=None, reduction_indices=None, keep_dims=None)\n",
      "    Computes the sum of elements across dimensions of a tensor. (deprecated arguments)\n",
      "    \n",
      "    Warning: SOME ARGUMENTS ARE DEPRECATED: `(keep_dims)`. They will be removed in a future version.\n",
      "    Instructions for updating:\n",
      "    keep_dims is deprecated, use keepdims instead\n",
      "    \n",
      "    Reduces `input_tensor` along the dimensions given in `axis`.\n",
      "    Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
      "    entry in `axis`. If `keepdims` is true, the reduced dimensions\n",
      "    are retained with length 1.\n",
      "    \n",
      "    If `axis` is None, all dimensions are reduced, and a\n",
      "    tensor with a single element is returned.\n",
      "    \n",
      "    For example:\n",
      "    \n",
      "    ```python\n",
      "    x = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
      "    tf.reduce_sum(x)  # 6\n",
      "    tf.reduce_sum(x, 0)  # [2, 2, 2]\n",
      "    tf.reduce_sum(x, 1)  # [3, 3]\n",
      "    tf.reduce_sum(x, 1, keepdims=True)  # [[3], [3]]\n",
      "    tf.reduce_sum(x, [0, 1])  # 6\n",
      "    ```\n",
      "    \n",
      "    Args:\n",
      "      input_tensor: The tensor to reduce. Should have numeric type.\n",
      "      axis: The dimensions to reduce. If `None` (the default), reduces all\n",
      "        dimensions. Must be in the range `[-rank(input_tensor),\n",
      "        rank(input_tensor))`.\n",
      "      keepdims: If true, retains reduced dimensions with length 1.\n",
      "      name: A name for the operation (optional).\n",
      "      reduction_indices: The old (deprecated) name for axis.\n",
      "      keep_dims: Deprecated alias for `keepdims`.\n",
      "    \n",
      "    Returns:\n",
      "      The reduced tensor, of the same dtype as the input_tensor.\n",
      "    \n",
      "    @compatibility(numpy)\n",
      "    Equivalent to np.sum apart the fact that numpy upcast uint8 and int32 to\n",
      "    int64 while tensorflow returns the same dtype as the input.\n",
      "    @end_compatibility\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.reduce_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function einsum in module tensorflow.python.ops.special_math_ops:\n",
      "\n",
      "einsum(equation, *inputs, **kwargs)\n",
      "    A generalized contraction between tensors of arbitrary dimension.\n",
      "    \n",
      "    This function returns a tensor whose elements are defined by `equation`,\n",
      "    which is written in a shorthand form inspired by the Einstein summation\n",
      "    convention.  As an example, consider multiplying two matrices\n",
      "    A and B to form a matrix C.  The elements of C are given by:\n",
      "    \n",
      "    ```\n",
      "      C[i,k] = sum_j A[i,j] * B[j,k]\n",
      "    ```\n",
      "    \n",
      "    The corresponding `equation` is:\n",
      "    \n",
      "    ```\n",
      "      ij,jk->ik\n",
      "    ```\n",
      "    \n",
      "    In general, the `equation` is obtained from the more familiar element-wise\n",
      "    equation by\n",
      "      1. removing variable names, brackets, and commas,\n",
      "      2. replacing \"*\" with \",\",\n",
      "      3. dropping summation signs, and\n",
      "      4. moving the output to the right, and replacing \"=\" with \"->\".\n",
      "    \n",
      "    Many common operations can be expressed in this way.  For example:\n",
      "    \n",
      "    ```python\n",
      "    # Matrix multiplication\n",
      "    >>> einsum('ij,jk->ik', m0, m1)  # output[i,k] = sum_j m0[i,j] * m1[j, k]\n",
      "    \n",
      "    # Dot product\n",
      "    >>> einsum('i,i->', u, v)  # output = sum_i u[i]*v[i]\n",
      "    \n",
      "    # Outer product\n",
      "    >>> einsum('i,j->ij', u, v)  # output[i,j] = u[i]*v[j]\n",
      "    \n",
      "    # Transpose\n",
      "    >>> einsum('ij->ji', m)  # output[j,i] = m[i,j]\n",
      "    \n",
      "    # Trace\n",
      "    >>> einsum('ii', m)  # output[j,i] = trace(m) = sum_i m[i, i]\n",
      "    \n",
      "    # Batch matrix multiplication\n",
      "    >>> einsum('aij,ajk->aik', s, t)  # out[a,i,k] = sum_j s[a,i,j] * t[a, j, k]\n",
      "    ```\n",
      "    \n",
      "    To enable and control broadcasting, use an ellipsis.  For example, to do\n",
      "    batch matrix multiplication, you could use:\n",
      "    \n",
      "    ```python\n",
      "    >>> einsum('...ij,...jk->...ik', u, v)\n",
      "    ```\n",
      "    \n",
      "    This function behaves like `numpy.einsum`, but does not support:\n",
      "    \n",
      "    * Subscripts where an axis appears more than once for a single input\n",
      "      (e.g. `ijj,k->ik`) unless it is a trace (e.g. `ijji`).\n",
      "    \n",
      "    Args:\n",
      "      equation: a `str` describing the contraction, in the same format as\n",
      "        `numpy.einsum`.\n",
      "      *inputs: the inputs to contract (each one a `Tensor`), whose shapes should\n",
      "        be consistent with `equation`.\n",
      "      name: A name for the operation (optional).\n",
      "    \n",
      "    Returns:\n",
      "      The contracted `Tensor`, with shape determined by `equation`.\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: If\n",
      "        - the format of `equation` is incorrect,\n",
      "        - the number of inputs implied by `equation` does not match `len(inputs)`,\n",
      "        - an axis appears in the output subscripts but not in any of the inputs,\n",
      "        - the number of dimensions of an input differs from the number of\n",
      "          indices in its subscript, or\n",
      "        - the input shapes are inconsistent along a particular axis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.einsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function conv2d in module tensorflow.python.ops.nn_ops:\n",
      "\n",
      "conv2d(input, filter=None, strides=None, padding=None, use_cudnn_on_gpu=True, data_format='NHWC', dilations=[1, 1, 1, 1], name=None, filters=None)\n",
      "    Computes a 2-D convolution given 4-D `input` and `filter` tensors.\n",
      "    \n",
      "    Given an input tensor of shape `[batch, in_height, in_width, in_channels]`\n",
      "    and a filter / kernel tensor of shape\n",
      "    `[filter_height, filter_width, in_channels, out_channels]`, this op\n",
      "    performs the following:\n",
      "    \n",
      "    1. Flattens the filter to a 2-D matrix with shape\n",
      "       `[filter_height * filter_width * in_channels, output_channels]`.\n",
      "    2. Extracts image patches from the input tensor to form a *virtual*\n",
      "       tensor of shape `[batch, out_height, out_width,\n",
      "       filter_height * filter_width * in_channels]`.\n",
      "    3. For each patch, right-multiplies the filter matrix and the image patch\n",
      "       vector.\n",
      "    \n",
      "    In detail, with the default NHWC format,\n",
      "    \n",
      "        output[b, i, j, k] =\n",
      "            sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]\n",
      "                            * filter[di, dj, q, k]\n",
      "    \n",
      "    Must have `strides[0] = strides[3] = 1`.  For the most common case of the same\n",
      "    horizontal and vertices strides, `strides = [1, stride, stride, 1]`.\n",
      "    \n",
      "    Args:\n",
      "      input: A `Tensor`. Must be one of the following types:\n",
      "        `half`, `bfloat16`, `float32`, `float64`.\n",
      "        A 4-D tensor. The dimension order is interpreted according to the value\n",
      "        of `data_format`, see below for details.\n",
      "      filter: A `Tensor`. Must have the same type as `input`.\n",
      "        A 4-D tensor of shape\n",
      "        `[filter_height, filter_width, in_channels, out_channels]`\n",
      "      strides: An int or list of `ints` that has length `1`, `2` or `4`.  The\n",
      "        stride of the sliding window for each dimension of `input`. If a single\n",
      "        value is given it is replicated in the `H` and `W` dimension. By default\n",
      "        the `N` and `C` dimensions are set to 1. The dimension order is determined\n",
      "        by the value of `data_format`, see below for details.\n",
      "      padding: Either the `string` `\"SAME\"` or `\"VALID\"` indicating the type of\n",
      "        padding algorithm to use, or a list indicating the explicit paddings at\n",
      "        the start and end of each dimension. When explicit padding is used and\n",
      "        data_format is `\"NHWC\"`, this should be in the form `[[0, 0], [pad_top,\n",
      "        pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used\n",
      "        and data_format is `\"NCHW\"`, this should be in the form `[[0, 0], [0, 0],\n",
      "        [pad_top, pad_bottom], [pad_left, pad_right]]`.\n",
      "      use_cudnn_on_gpu: An optional `bool`. Defaults to `True`.\n",
      "      data_format: An optional `string` from: `\"NHWC\", \"NCHW\"`.\n",
      "        Defaults to `\"NHWC\"`.\n",
      "        Specify the data format of the input and output data. With the\n",
      "        default format \"NHWC\", the data is stored in the order of:\n",
      "            [batch, height, width, channels].\n",
      "        Alternatively, the format could be \"NCHW\", the data storage order of:\n",
      "            [batch, channels, height, width].\n",
      "      dilations: An int or list of `ints` that has length `1`, `2` or `4`,\n",
      "        defaults to 1. The dilation factor for each dimension of`input`. If a\n",
      "        single value is given it is replicated in the `H` and `W` dimension. By\n",
      "        default the `N` and `C` dimensions are set to 1. If set to k > 1, there\n",
      "        will be k-1 skipped cells between each filter element on that dimension.\n",
      "        The dimension order is determined by the value of `data_format`, see above\n",
      "        for details. Dilations in the batch and depth dimensions if a 4-d tensor\n",
      "        must be 1.\n",
      "      name: A name for the operation (optional).\n",
      "      filters: Alias for filter.\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor`. Has the same type as `input`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(\n",
    "    np.array(\n",
    "        [\n",
    "            [[1,2,3],\n",
    "             [4,5,6],\n",
    "             [7,8,9]\n",
    "            ],\n",
    "            [[-1,-2,-3],\n",
    "             [-4,-5,-6],\n",
    "             [-7,-8,-9]\n",
    "            ],\n",
    "            [[1.2,2.2,3.2],\n",
    "             [4.2,5.2,6.2],\n",
    "             [7.2,8.2,9.2]\n",
    "            ],\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.concat([a, a,], axis=2)\n",
    "c = tf.reshape(b, [3,6,3])\n",
    "\n",
    "d = tf.transpose(c, perm=[0, 2, 1])\n",
    "e = tf.concat([d, d], axis=2)\n",
    "f = tf.transpose(tf.reshape(e, [3, 6, 6]), perm=[0, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1. ,  2. ,  3. ],\n",
       "        [ 1. ,  2. ,  3. ],\n",
       "        [ 4. ,  5. ,  6. ],\n",
       "        [ 4. ,  5. ,  6. ],\n",
       "        [ 7. ,  8. ,  9. ],\n",
       "        [ 7. ,  8. ,  9. ]],\n",
       "\n",
       "       [[-1. , -2. , -3. ],\n",
       "        [-1. , -2. , -3. ],\n",
       "        [-4. , -5. , -6. ],\n",
       "        [-4. , -5. , -6. ],\n",
       "        [-7. , -8. , -9. ],\n",
       "        [-7. , -8. , -9. ]],\n",
       "\n",
       "       [[ 1.2,  2.2,  3.2],\n",
       "        [ 1.2,  2.2,  3.2],\n",
       "        [ 4.2,  5.2,  6.2],\n",
       "        [ 4.2,  5.2,  6.2],\n",
       "        [ 7.2,  8.2,  9.2],\n",
       "        [ 7.2,  8.2,  9.2]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1. ,  1. ,  2. ,  2. ,  3. ,  3. ],\n",
       "        [ 1. ,  1. ,  2. ,  2. ,  3. ,  3. ],\n",
       "        [ 4. ,  4. ,  5. ,  5. ,  6. ,  6. ],\n",
       "        [ 4. ,  4. ,  5. ,  5. ,  6. ,  6. ],\n",
       "        [ 7. ,  7. ,  8. ,  8. ,  9. ,  9. ],\n",
       "        [ 7. ,  7. ,  8. ,  8. ,  9. ,  9. ]],\n",
       "\n",
       "       [[-1. , -1. , -2. , -2. , -3. , -3. ],\n",
       "        [-1. , -1. , -2. , -2. , -3. , -3. ],\n",
       "        [-4. , -4. , -5. , -5. , -6. , -6. ],\n",
       "        [-4. , -4. , -5. , -5. , -6. , -6. ],\n",
       "        [-7. , -7. , -8. , -8. , -9. , -9. ],\n",
       "        [-7. , -7. , -8. , -8. , -9. , -9. ]],\n",
       "\n",
       "       [[ 1.2,  1.2,  2.2,  2.2,  3.2,  3.2],\n",
       "        [ 1.2,  1.2,  2.2,  2.2,  3.2,  3.2],\n",
       "        [ 4.2,  4.2,  5.2,  5.2,  6.2,  6.2],\n",
       "        [ 4.2,  4.2,  5.2,  5.2,  6.2,  6.2],\n",
       "        [ 7.2,  7.2,  8.2,  8.2,  9.2,  9.2],\n",
       "        [ 7.2,  7.2,  8.2,  8.2,  9.2,  9.2]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(tf.reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(tf.tile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(tf.transpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use matmuls for upsampling, see whiteboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
