{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.5/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(np.random.rand(3, 2, 2, 5), dtype=tf.float32)\n",
    "x = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.21668193, 0.05288194, 0.94911677, 0.62078345, 0.59650975],\n",
       "         [0.610115  , 0.3216673 , 0.37463936, 0.09343854, 0.16760853]],\n",
       "\n",
       "        [[0.200176  , 0.05431966, 0.13389105, 0.92559135, 0.71663034],\n",
       "         [0.1216267 , 0.86508805, 0.8859746 , 0.89444184, 0.04948702]]],\n",
       "\n",
       "\n",
       "       [[[0.57157767, 0.32710466, 0.06847334, 0.9089573 , 0.86125726],\n",
       "         [0.43229046, 0.56822634, 0.3672753 , 0.06501245, 0.26721212]],\n",
       "\n",
       "        [[0.7549424 , 0.69279325, 0.00627291, 0.74134314, 0.4837768 ],\n",
       "         [0.10510538, 0.78369117, 0.03127609, 0.9086586 , 0.33178547]]],\n",
       "\n",
       "\n",
       "       [[[0.8699226 , 0.04992506, 0.4703832 , 0.5484367 , 0.6916662 ],\n",
       "         [0.8986387 , 0.79851395, 0.3341791 , 0.67818516, 0.7345151 ]],\n",
       "\n",
       "        [[0.70913076, 0.755777  , 0.04884446, 0.1827714 , 0.37749782],\n",
       "         [0.07498696, 0.5757642 , 0.7027297 , 0.78859097, 0.7415668 ]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = tf.reshape(x, [12, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#d = tf.pad(c, [[0, 1], [0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sess.run(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = np.array([[1, 1], [1, 1]], dtype=np.float32)\n",
    "inH = x.shape[1]\n",
    "inW = x.shape[2]\n",
    "minorDim = x.shape[3]\n",
    "padx0=0\n",
    "pady0=0\n",
    "padx1=0\n",
    "pady1=0\n",
    "upx = 2\n",
    "upy = 2\n",
    "kernelH, kernelW = k.shape\n",
    "x = tf.reshape(x, [-1, inH, 1, inW, 1, minorDim])\n",
    "#x = tf.pad(x, [[0, 0], [0, 0], [0, upy - 1], [0, 0], [0, upx - 1], [0, 0]])\n",
    "x = tf.pad(x, [[0, 0], [0, 0], [0, upy - 1], [0, 0], [0, upx - 1], [0, 0]])\n",
    "x = tf.reshape(x, [-1, inH * upy, inW * upx, minorDim])\n",
    "\n",
    "# Convolve with filter.\n",
    "x = tf.transpose(x, [0, 3, 1, 2])\n",
    "x = tf.reshape(x, [-1, 1, inH * upy + pady0 + pady1, inW * upx + padx0 + padx1])\n",
    "w = tf.constant(k[:, :, np.newaxis, np.newaxis], dtype=x.dtype)\n",
    "x = tf.pad(x, [[0, 0], [0, 0], [1, 0], [1, 0]])\n",
    "y = tf.nn.conv2d(x, w, padding='VALID', data_format='NCHW', strides=1)\n",
    "#y = tf.nn.conv2d(tf.transpose(x, [0, 2, 3, 1]), w, padding='SAME')\n",
    "z = tf.transpose(x, [0, 2, 3, 1])\n",
    "#x = tf.reshape(x, [-1, minorDim, inH * upy + pady0 + pady1 - kernelH + 1, inW * upx + padx0 + padx1 - kernelW + 1])\n",
    "#x = tf.transpose(x, [0, 2, 3, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out = sess.run(x)\n",
    "y_out = sess.run(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(15), Dimension(1), Dimension(5), Dimension(5)])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.21668193, 0.        , 0.610115  , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.200176  , 0.        , 0.1216267 , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_out[0, 0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21668193, 0.610115  ],\n",
       "       [0.200176  , 0.1216267 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(a[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21668193, 0.21668193, 0.610115  , 0.610115  ],\n",
       "       [0.21668193, 0.21668193, 0.610115  , 0.610115  ],\n",
       "       [0.200176  , 0.200176  , 0.1216267 , 0.1216267 ],\n",
       "       [0.200176  , 0.200176  , 0.1216267 , 0.1216267 ]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_out[0, 0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 5, 5, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = tf.transpose(x, [0, 2, 3, 1])\n",
    "sess.run(z).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[1.]],\n",
       "\n",
       "        [[1.]]],\n",
       "\n",
       "\n",
       "       [[[1.]],\n",
       "\n",
       "        [[1.]]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function conv2d in module tensorflow.python.ops.nn_ops:\n",
      "\n",
      "conv2d(input, filter=None, strides=None, padding=None, use_cudnn_on_gpu=True, data_format='NHWC', dilations=[1, 1, 1, 1], name=None, filters=None)\n",
      "    Computes a 2-D convolution given 4-D `input` and `filter` tensors.\n",
      "    \n",
      "    Given an input tensor of shape `[batch, in_height, in_width, in_channels]`\n",
      "    and a filter / kernel tensor of shape\n",
      "    `[filter_height, filter_width, in_channels, out_channels]`, this op\n",
      "    performs the following:\n",
      "    \n",
      "    1. Flattens the filter to a 2-D matrix with shape\n",
      "       `[filter_height * filter_width * in_channels, output_channels]`.\n",
      "    2. Extracts image patches from the input tensor to form a *virtual*\n",
      "       tensor of shape `[batch, out_height, out_width,\n",
      "       filter_height * filter_width * in_channels]`.\n",
      "    3. For each patch, right-multiplies the filter matrix and the image patch\n",
      "       vector.\n",
      "    \n",
      "    In detail, with the default NHWC format,\n",
      "    \n",
      "        output[b, i, j, k] =\n",
      "            sum_{di, dj, q} input[b, strides[1] * i + di, strides[2] * j + dj, q]\n",
      "                            * filter[di, dj, q, k]\n",
      "    \n",
      "    Must have `strides[0] = strides[3] = 1`.  For the most common case of the same\n",
      "    horizontal and vertices strides, `strides = [1, stride, stride, 1]`.\n",
      "    \n",
      "    Args:\n",
      "      input: A `Tensor`. Must be one of the following types:\n",
      "        `half`, `bfloat16`, `float32`, `float64`.\n",
      "        A 4-D tensor. The dimension order is interpreted according to the value\n",
      "        of `data_format`, see below for details.\n",
      "      filter: A `Tensor`. Must have the same type as `input`.\n",
      "        A 4-D tensor of shape\n",
      "        `[filter_height, filter_width, in_channels, out_channels]`\n",
      "      strides: An int or list of `ints` that has length `1`, `2` or `4`.  The\n",
      "        stride of the sliding window for each dimension of `input`. If a single\n",
      "        value is given it is replicated in the `H` and `W` dimension. By default\n",
      "        the `N` and `C` dimensions are set to 1. The dimension order is determined\n",
      "        by the value of `data_format`, see below for details.\n",
      "      padding: Either the `string` `\"SAME\"` or `\"VALID\"` indicating the type of\n",
      "        padding algorithm to use, or a list indicating the explicit paddings at\n",
      "        the start and end of each dimension. When explicit padding is used and\n",
      "        data_format is `\"NHWC\"`, this should be in the form `[[0, 0], [pad_top,\n",
      "        pad_bottom], [pad_left, pad_right], [0, 0]]`. When explicit padding used\n",
      "        and data_format is `\"NCHW\"`, this should be in the form `[[0, 0], [0, 0],\n",
      "        [pad_top, pad_bottom], [pad_left, pad_right]]`.\n",
      "      use_cudnn_on_gpu: An optional `bool`. Defaults to `True`.\n",
      "      data_format: An optional `string` from: `\"NHWC\", \"NCHW\"`.\n",
      "        Defaults to `\"NHWC\"`.\n",
      "        Specify the data format of the input and output data. With the\n",
      "        default format \"NHWC\", the data is stored in the order of:\n",
      "            [batch, height, width, channels].\n",
      "        Alternatively, the format could be \"NCHW\", the data storage order of:\n",
      "            [batch, channels, height, width].\n",
      "      dilations: An int or list of `ints` that has length `1`, `2` or `4`,\n",
      "        defaults to 1. The dilation factor for each dimension of`input`. If a\n",
      "        single value is given it is replicated in the `H` and `W` dimension. By\n",
      "        default the `N` and `C` dimensions are set to 1. If set to k > 1, there\n",
      "        will be k-1 skipped cells between each filter element on that dimension.\n",
      "        The dimension order is determined by the value of `data_format`, see above\n",
      "        for details. Dilations in the batch and depth dimensions if a 4-d tensor\n",
      "        must be 1.\n",
      "      name: A name for the operation (optional).\n",
      "      filters: Alias for filter.\n",
      "    \n",
      "    Returns:\n",
      "      A `Tensor`. Has the same type as `input`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.nn.conv2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5.2 64-bit",
   "language": "python",
   "name": "python35264bit3e2f71d9b2304cb2afdd83261d0ec349"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
